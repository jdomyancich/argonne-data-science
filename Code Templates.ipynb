{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad33e31a-e88f-4171-a3f7-9d80c6c69abb",
   "metadata": {},
   "source": [
    "# How to Use this Notebook\n",
    "___\n",
    "\n",
    "This notebook is meant to provide both a template for writing your own notebooks and examples of how the template can be applied using a dataset from the NOAA's Global Historical Climatology Network (GHCN) to investigate climate change. While there is no set recipe of how data science is done or shown in a Jupyter notebook, this notebook highlights some fundamental tasks when working with data and the general order in which they are often performed:\n",
    "- Importing\n",
    "- Cleaning\n",
    "- Exploring\n",
    "- Analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2515456-2cf6-4fa0-8eaa-37d096f30e85",
   "metadata": {},
   "source": [
    "### The Templates\n",
    "\n",
    "In each use case, a template is given that shows the structure of the code with placeholders shown as `<missing_code>`. For example, if you come across `<variable_name>` or `<input_value>`, it suggests that you should replace it with an appropriate variable name or input value relevant to your specific use case. This is a common practice when writing code for illustrative purposes. While these placeholders are not valid Python syntax, they serve as a visual cue to indicate the section that requires user customization.\n",
    "\n",
    "Sometimes, the angle brackets `< >` are not needed when it is obvious that generic code is being used. This is most often the case when assigning variables. This makes the template less cluttered and easier to interpret. For example, the following cell uses angle brackets to call out the `file_path`, but brackets are not needed to identify the variable where the data is stored, `dataframe_name`. \n",
    "\n",
    "`dataframe_name = pd.read_csv('<file_path>')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0548fa79-bf84-4993-b2f3-398e5b80393c",
   "metadata": {},
   "source": [
    "### The Examples\n",
    "\n",
    "When there are large sections of missing code, comments are often use to describe what is to be added.\n",
    "Following each template, working code is provided that replaces the `<missing_code>` with code that works for the GHCN data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941b458-1d5b-4f27-a681-1927af1dbffd",
   "metadata": {},
   "source": [
    "# Importing\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4f588f-a139-491c-bcb1-c451c9cfe605",
   "metadata": {},
   "source": [
    "### Importing the Libraries\n",
    "\n",
    "There are over 200,000 Python libraries available. The type of data and what you will do with it determine which libraries you need. However, there are some popular libraries that are commonly used:\n",
    "\n",
    "- NumPy: scientific computing\n",
    "- Pandas: data analysis and manipulation\n",
    "- Matplotlib: visualizations\n",
    "- SciPy: more scientific computing\n",
    "\n",
    "The necessary libraries are often imported at the beginning of the notebook and are \"imported as\" using an abbreviation. The abbreviation allows us to use the library with less code. You can choose whatever abbreviation you want, but most libraries have a commonly accepted one. However, they don't have to be abbreviated (as is often the case with SciPy).\n",
    "\n",
    "Notice that a special version of matplotlib called `pyplot` is often used. Pyplot makes using matplotlob easier in Jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f8476-511a-453b-a865-ea528467e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d58d0-52ad-4159-bbcd-161457175600",
   "metadata": {},
   "source": [
    "### Importing the Data\n",
    "\n",
    "Datasets may be stored \"locally\" on your computer or \"in the cloud\" on a server in a variety of file formats. Comma separated values (.csv) is the most common format.\n",
    "\n",
    "The data must be brought into the computer's memory and stored in a variable. Pandas has a function called `read_csv` that converts a .csv file into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3c1cb0-0cd6-4019-b82b-c2436d823289",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name = pd.read_csv('<dataset_location>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93b624-7082-498e-9406-01192963d06a",
   "metadata": {},
   "source": [
    "The `dataset_location` can be a location on your computer, called a \"file path\", or a web address (url). In this notebook, we are running Jupyter on a remote server. In other words, it's like we have our own computer that exists in the cloud. This allows us to use a computer that probably has a lot more memory and computing power than the laptop or chromebook that you may be using now.  \n",
    "\n",
    "Writing the correct file path for your .csv file can be difficult. The best place to start is to determine the \"present working directory\" of this Jupyter notebook. This is the file path of the folder that our notebook \"lives\" in. We use something called a \"magic command\" to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39b9a6-fbb9-42fd-84fb-ab70f37220f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660e719-5f40-442f-b0e4-5a4417f7584e",
   "metadata": {},
   "source": [
    "You can decipher this by looking at the file browser pane to the left. This notebook, `Code_Templates.ipynb` sits in the file path given by `%pwd`. You will notice there is a folder called `Datasets`. If we want to tell Pandas the location of the data, all we need to do is insert the file name of the .csv file into the following. Notice that we don't have to provide the full file path because our present working directory already takes us to the `content` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce34b56-6fcd-4b37-a968-5b68082899c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name = pd.read_csv('<dataset folder name>/<csv file name>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e738fa6-a258-4ff1-841f-b3f43822b932",
   "metadata": {},
   "source": [
    "If you double-click the `Datasets` folder, you will see the available .csv files.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6507e1c9-cc43-4941-a925-c6d0394f459a",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Let’s start exploring weather data! Within this notebook, you will learn how to work with the GHCNd dataset. The Global Historical Climatology Network daily (GHCNd) is an integrated database of daily climate summaries from land surface stations across the globe, including Chicago.\n",
    "\n",
    "Read in the `midway.csv` file into a variable called `midway`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dfbaee-2c41-4704-a587-08dfd60cdd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edb70c4a-18a1-46ec-af82-45b874998846",
   "metadata": {},
   "source": [
    "\n",
    "# Cleaning Data\n",
    "___\n",
    "\n",
    "Next we’re going to clean up the data. A raw dataset can be very messy. Data may be labeled strangely, formatted incorrectly or missing altogether. When we \"clean\" data, we are fixing these problems with the goal of creating a new dataset that is easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255eee5a-b834-4361-9604-2731335948e0",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "Sometimes the original column names are confusing. You can change them by setting a list of new column names to `data.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b6e44-68d8-4b06-bb35-cc49e8354350",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name.columns = ['column_1_name', 'column_2_name', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45836bfa-f4a6-4ad7-9082-4f4efc145677",
   "metadata": {},
   "source": [
    "It is important to be consistent in how you name columns. Here are a few recommendations:\n",
    "\n",
    "- Continue using `snake_case`. Capitalization in variable and column names is a detail that students often miss.\n",
    "- Choose column names that are both short and descriptive. Students should immediately know what the name means.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2369248-ddda-4495-a7bf-39f12c48ff78",
   "metadata": {},
   "source": [
    "In this dataset, the column names are in all caps which will be difficult to type. Also, we may be able to figure out what `PRCP`, `TMAX` and `TMIN` mean, but there is a good chance the student may not. Therefore, we can make the columns names a little easier to interpret and type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f2bfa-f772-4fc9-9b3d-458e1e356dab",
   "metadata": {},
   "source": [
    "Also, some of these column names could include the units. As can probably be inferred, the temperatures are in Celsius. However, `precip` is unclear. This is where the [documentation](https://www.ncei.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf) for the data source is important. In this case, precipitation is measured in millimeters (mm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a2347-667b-494f-8b58-f534ce769964",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example\n",
    "\n",
    "Let's make the column names more intuitive and add the united to the measurements.\n",
    "\n",
    "Rename `PRCP` as `precil_mm`, `TMAX` as `high_temp_C`, and `TMIN` as `low_temp_C`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a62bf-c3c5-45e8-82cc-12bac9deb836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd31eee8-b589-421f-ae8b-95be6dc38c36",
   "metadata": {},
   "source": [
    "## Converting to Datetime\n",
    "\n",
    "Dates and time can be confusing when coding because the computer needs to use a specific data type to work with, called **datetime**. Datetime allows us to sort and select entries in the dataset and make plots (charts) showing how a variable changes with time. However, you cannot assume that just because data looks like a date, that the computer sees it that way.\n",
    "\n",
    "It is often helpful to use Python's built-in `type` function to check the data type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1ef68-fb71-46f9-9dd2-16463544e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(<location_of_data>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b19de5-6b35-4033-9d04-8762d5e0b5e4",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab2c87b-8d3b-4dee-8e0e-67913e52cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(midway.loc[0, 'date'])  # .loc[0, 'date'] tells the computer to only look at the first row of the 'date' column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538455aa-9b15-44e0-87ac-ccf19b3834c7",
   "metadata": {},
   "source": [
    "To the computer, a string is simply a piece of text. It does not have any useful mathematical meaning. Fortunately, Pandas has a function called `to_datetime` that converts dates and times into the datetime data type. Notice below that we reference a column in a dataframe with the following syntax: `dataframe_name['column_name']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ffb37-97a3-4188-a4ff-d530cf406d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "midway['date'] = pd.to_datetime(midway['date']) # converts the entire 'date' column to datetime\n",
    "midway.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e853b2bd-3516-405c-9fcb-809b160b097b",
   "metadata": {},
   "source": [
    "Notice the dates look the same. However, let's check the data type again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9acad2-951e-4d0f-be2b-86f459bd552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(midway.loc[0, 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722b1f0-67ed-4f99-9aa1-d905ffe8abb2",
   "metadata": {},
   "source": [
    "## Setting the Index\n",
    "\n",
    "The **index** is how the data is ordered. In a dataframe, the index is the first column and is in bold. By default, the index starts at 0 and increases by whole numbers. However, when we work with data that has been measured by time, we will usually want time to be our index.\n",
    "\n",
    "We can make one of our columns the index using the `set_index` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab0b9b-90fa-425b-8336-09c88b715bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name = dataframe_name.set_index('<column that you want to become index>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82dcaa9-1dbd-4aa3-9c81-df346d144eae",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Set the `date` column as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3239222-6156-4319-ad92-95af86421da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "763d9ace-a8bd-448a-b8c7-e4ff16002970",
   "metadata": {},
   "source": [
    "While a little tedious, changing the index to datetime is necessary for us to explore how the data changes with respect to time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ecf97-460f-44af-aeaa-d7347a4a0646",
   "metadata": {},
   "source": [
    "## Filtering Columns\n",
    "\n",
    "Often, the original data contains more information than needed. Therefore, creating new dataframes that only contain the columns that will be used moving forward is a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3068a-54ac-4a89-9f8e-134ea0fa8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe_name = old_dataframe_name[['new_column_1', 'new_column_2', ...]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9e21e-2ea4-4fd7-83fe-d0c82e1ac47f",
   "metadata": {},
   "source": [
    "The double brackets, `[[`,  are confusing. If we were filtering just one column, we would use a single bracket, `[`. However, if you want to filter mutiple columns, you must pass a list inside the first set of brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba52ac4-2df8-416b-9460-47d6745b210b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a237e61-431d-462d-9f02-8303be588248",
   "metadata": {},
   "source": [
    "Let's focus on just the high and low temperatures.\n",
    "\n",
    "Create a new dataframe called `filtered_midway` that contains only the `high_temp_C` and `low_temp_C` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b03ea-9d66-483f-af29-d71d028ef2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e85251c1-5dbc-49f6-9a98-880e544ea001",
   "metadata": {},
   "source": [
    "Notice that we assigned this smaller dataset to a new variable, `filtered_midway`. This preserves the original dataframe in the `midway` variable so we can access it, if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08213172-c5ad-4ad0-b342-1219b78cfac7",
   "metadata": {},
   "source": [
    "### Generating New Data\n",
    "While the data may be in a much better state than what we started with, it is often necessary to create new data using the existing dataset for a variety of reasons. Perhaps the a outcome variabnle needs to be normalized or the units converted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12d671-50c8-4530-b2d2-89917df59df1",
   "metadata": {
    "tags": []
   },
   "source": [
    "These calculations are often written as **functions** that take one or more inputs (known as parameters) and output or \"return\" a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6799fcb7-52e7-48b6-b8a3-9cb03aa78db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_name(parameter_1, parameter_2, ...):\n",
    "    # insert calculation here using the inputs as variables\n",
    "    return output_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08411f11-ac9e-408b-aa6b-1370c2897736",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e65b4-60e6-4801-903a-e0104644c0fb",
   "metadata": {},
   "source": [
    "While we often encourage students to use the metric system, their intuition of \"hot\" and \"cold\" temperature is based on the imperial system. Therefore, we can convert the temperatures to Fahrenheit. \n",
    "\n",
    "Because the Celsius to Fahrenheit calculation needs to be done many times, we can define a function.\n",
    "\n",
    "Define a function called `cel_to_far` that takes an input, `temp_C` and returns `temp_F`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce41e88-54d3-404a-abc2-7f7dc5536aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21589479-4d71-4966-a02e-b0631e98ec5c",
   "metadata": {},
   "source": [
    "Defining the function doesn't appear to do anything, but we have actually taught the computer how to take an input, `temp_C`, and give us an output, `temp_F`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c21e5-a6cc-4caa-9178-20ac79eeddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel_to_fahr(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daace72b-0ccc-4d4f-b497-e7dce23338c2",
   "metadata": {},
   "source": [
    "Here is where Pandas is really powerful. If we want to convert all of our Celsius temperatures to Fahrenheit, we have to repeat the calculation over 33,000 times! Fortunately, we only need to tell the computer once by putting the column we want to convert into the function. \n",
    "\n",
    "In the following example, we are placing the output of the function into a new column called `high_temp_F`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159e3642-e9ee-415e-afb8-2721052cecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_midway['high_temp_F'] = cel_to_fahr(filtered_midway['high_temp_C'])\n",
    "filtered_midway.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ba418-229c-406a-aa35-810101106460",
   "metadata": {},
   "source": [
    "**Try it yourself**: Make a new column called `low_temp_F` for low temps in Fahrenheit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d0de6-b5ef-4ce5-98fb-1f9828bece62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e0f34a-d6d7-4c04-a94b-055d3aa1c9d9",
   "metadata": {},
   "source": [
    "# Exploring the Data\n",
    "___\n",
    "The work of cleaning the data (often called \"wrangling\") usually takes up most of the data scientist's time. However, the investment of time in getting the data in a workable state makes the exploration of the data much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c9beaf-617e-4724-9151-a8cab6e3a2b4",
   "metadata": {},
   "source": [
    "### Summarizing the Data\n",
    "\n",
    "There are many methods to summarize and describe the data. We will just scratch the surface here, but will highlight some of the more common methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3863c8a-f53f-494c-9c03-d09b0aa059e6",
   "metadata": {},
   "source": [
    "**Descriptive statistics** provide a summary of data. The most commonly known examples are measures of central tendency (mean, median and mode), maximum, minimum and standard deviation.\n",
    "\n",
    "| Name | Function |\n",
    "|-------|-------|\n",
    "| minumum | `.min()` |\n",
    "| maximum | `.max()` |\n",
    "| mean | `.mean()` |\n",
    "| median | `.median()` |\n",
    "| mode | `.mode()` |\n",
    "| standard deviation | `.std()` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e9936-9cf5-403e-88c9-37fe3d97fa11",
   "metadata": {},
   "source": [
    "Applying these functions is simply a matter of calling the column you want to describe and following it with `.function()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191fac9f-b53c-495b-a4c0-a2008712435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name['column_name'].<function>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0706b-fbf0-4f6b-8d17-5c7410070848",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Suppose we wanted to determine the hottest temperature ever recorded at Midway airport. \n",
    "\n",
    "Use the appropriate function to calculate the maximum high temperature in Fahrenheit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e6160-6555-4926-8ebc-866700a34bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae32eede-0194-4f63-a85f-7f69a766bbbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Filtering Rows\n",
    "\n",
    "There may be certain rows we are interested in as well. Rows are a little trickier to reference because they are not arrays. In columns, we can reference the name of the columns that we are interested in. Also, the elements (entries) in a column are the same data type. Since rows contain the elements of several different arrays, they can contain multiple data types and require a different way of thinking. We can filter rows two ways: by index or by label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66daab1-cf65-4e15-8d7e-aefe1079741d",
   "metadata": {},
   "source": [
    "#### Filtering by Label\n",
    "\n",
    "Sometimes, you will want only the rows that contain a certain value or range of values contained within a column. This is done by using **conditional** statements. The following operators are used:\n",
    "\n",
    "| Name | Operator |\n",
    "|-------|-------|\n",
    "| equal to | `==` |\n",
    "| not equal to | `!=` |\n",
    "| greater than | `>` |\n",
    "| greater than or equal to | `>=` |\n",
    "| less than | `<` |\n",
    "| less than or equal to | `<=` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c6a19-e6df-4b6b-8b46-a05d8151e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = old_dataframe[(old_dataframe['column_name'] <operator> <value_or_label>)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047cadc-0841-439e-81eb-3cd288148baf",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8033168-8a55-475b-897e-309a2aae8aeb",
   "metadata": {},
   "source": [
    "Suppose we are interested in identifying the days where the temperature was 100 degrees F or higher.\n",
    "\n",
    "Filter out the days where the temperature was greater than or equal to 100 degrees F and place it in a variable called `hund_deg_days`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a15860-96d1-4782-a3b1-bfa276f063fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fc49f43-9152-40ba-b969-21de5f9890d2",
   "metadata": {},
   "source": [
    "#### Fine Tuning\n",
    "\n",
    "The conditional can be made more selective using the `&` (and) or `|` (or) operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea59e74-eace-414c-b0d9-7b5acb46f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = old_dataframe[(old_dataframe['column_name'] <operator> <value_or_label>) & (old_dataframe['column_name'] <operator> <value_or_label>)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb81d2-06d5-4c47-9809-219c7f9e547c",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "If we wanted to see days that were between 102 and 103 degrees, we can use the `&` (and) conditional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7424727-805f-41a4-9004-dfae6b6183e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_102 = filtered_midway[(filtered_midway['high_temp_F'] >= 102) & (filtered_midway['high_temp_F'] <= 103)]\n",
    "days_102"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0366662-f288-419b-8997-19ea467d309c",
   "metadata": {},
   "source": [
    "#### Filtering by Index\n",
    "\n",
    "The advantage of making datetime our index is that we can filter a particular day or range of dates. There are many ways to do this, but here we will use an **attribute** of the datetime index. There are many attributes of the datetime index, such as `year`, `month` and `day`. There can all be found [here](https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9bfa7-e05e-4a67-83b8-d12086e2acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframe = old_dataframe[old_dataframe.index.<attribute> <operator> <value>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed77e4a2-837e-4c34-a688-4f6a10ecd9fc",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89221c4c-2df0-4c36-bf2b-c002be289a82",
   "metadata": {},
   "source": [
    "Remember back to our introduction to climate change and weather events. There was a news article from Block Club Chicago that noted March 4th 2019 was the coldest March 4th in 129 years! If March 4th 2019 was the coldest March 4th in 129 years, we are interested in one day in particular: March 4. In order to do this we will want only those rows for March 4. \n",
    "\n",
    "<img src = 'imgs/march_cold.png' width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c0704c-791b-45ac-9e4e-acaa50502236",
   "metadata": {},
   "source": [
    "First we can filter out the March dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208e0b0-1a8e-41ef-b6c3-57bb3e32225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "march = filtered_midway[filtered_midway.index.month == 3]\n",
    "march.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c6f28-d8cd-4ae5-a094-2bdb6f03d664",
   "metadata": {},
   "source": [
    "**Try it yourself**: Make a dataframe called `march_4` for all records for March 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420ac4d-3cc8-4ff2-b42a-cd474a152997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921d70f2-fa7d-44f2-b8cf-a6c61a029009",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "While data in tables and the output of functions is one way of exploring the data, a more accessible way is the creation of visualizations. These allow us to easily see outliers and patterns in the data.\n",
    "\n",
    "Visualizing is a whole new world of coding. A variety of visualizations are available: plots, histograms, and scatterplots, to name a few. Here we will make a simple **plot** (line graph) using the Matplotlib library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a24e19-26af-4d18-93c9-3a9b06c5d37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = dataframe_name.index.<attribute>\n",
    "y_axis = dataframe_name['column_name']\n",
    "\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.xlabel('<x_axis_label>')\n",
    "plt.ylabel('<y_axis_label>')\n",
    "plt.title('<title>')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d357c-ab34-4eea-a333-5637ca6dead9",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "March 4th 2019 was the coldest March 4th in 129 years! Can we spot March 4th 2019 in our data?\n",
    "\n",
    "Create a line plot of low temperatures for March 4 for every year in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ff017-d008-413d-b29f-db8e1bff00d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b2d7288-b047-4dd0-8dfe-b029ef4fae04",
   "metadata": {},
   "source": [
    "## Try it yourself:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d09bd5-c16b-45d9-9246-b4d1fe8c9287",
   "metadata": {},
   "source": [
    "“Remember back to our introduction to climate change and weather events. There was a news article from Block Club Chicago that noted April 13, 2023 was the hottest April 13th in 138 years! Can we spot April 13, 2023 in our data?”\n",
    "\n",
    "<img src = 'imgs/april_hot.png' width = 400>\n",
    "\n",
    "Starting with the midway.csv file, build your own notebook. Avoid the temptation to copy and paste cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4336370-8c2d-4e7e-b41f-a3650943159d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129bed42-327a-41f7-9385-fdd9a76499cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52ea111d-1206-4420-8665-e6e1ea2f5645",
   "metadata": {},
   "source": [
    "The following sections are under construction :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab10f48-ee91-44ed-9654-62cb49033907",
   "metadata": {},
   "source": [
    "## Single Calculation (30 year average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4557165-46be-4ebe-9b5a-ffeaf921b321",
   "metadata": {},
   "source": [
    "## Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88212c58-3d3e-4def-9ab0-ee60aa6bc3d3",
   "metadata": {},
   "source": [
    "### Best Fit Lines and R-values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468aa05-e17f-4679-b7d5-ae6e7565c763",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66eb09-5456-40f3-a49c-f9b009e1942b",
   "metadata": {},
   "source": [
    "## Building Contingency Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f941d9-7d3f-4968-8ebf-736db19686ad",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e0de9-eb1c-400f-b3e3-958bb681c195",
   "metadata": {},
   "source": [
    "## P-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd2af40-917b-452b-b623-0aab54a309d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
